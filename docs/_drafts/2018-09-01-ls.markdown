---
layout: post
title:  "ls > txt"
date:   2018-9-1 11:00:00 -0700
categories: linux kernel bash deep_dive
---
<h1>Overview</h1>

<p>
At one point in my career I was interviewing for a company whos name I'm not going to mention.  The entire interview
revolved around one tiny string of text:
</p>

{% highlight shell %}
ls > txt
{% endhighlight %}

<p>
That's it, that's the command.  The majority of the 1-hour interview was spent on talking about every single thing
that happens with this command after the user presses enter.  Before we begin, I want to say that this is probably 
the absolute worst way to determine long-term success at a company. Mainly because this is something that we 
don't use during our day-to-day operations.  Most of what we actually need at the job is a positive 
attitude and a sense of humor.  Everything else is usually taught or learned as needed.
</p>

<p>
With that said, this is meant to be fun and maybe a little entertaining.  It's possible that I'm missing out on some
details, if you catch something, let me know so I can make the document as complete as possible.  I'll make sure I 
put your name in the credits of any edits.  I enjoy doing deep dives like this because it gives me a chance
to really dig into the inner workings of what happens "behind the curtain."
</p>

<h1>Phase 1: bash</h1>

<a href="http://git.savannah.gnu.org/cgit/bash.git/tree/parse.y">Parse</a>

<p>
To start this journey we're going to assume that we're in an active bash shell.  We're going to skip over the parts
about how we got to this point, as in, how the kernel came to be, and how shell was loaded into memory.  We'll get
around to these mechanics in a latter part of this session.  For now we're going to focus on exactly what bash is going
to do and how it's going to do it.
</p>

<p>
One of my favorite moments of my career ( and there are many ) was watching Dr. Vogels give the keynote talk at Re:Invent
2016.  This was the year AWS announced Lambda.  He described the purpose of Lambda by describing the high-level pardaigm
for pretty much everything in computer science: input, business logic, and output ( or outcome ).  These 3 items are
the basis for almost everything we do.  In this case, bash, the obiquitus workhorsse of IT and operations folks is no different.
</p>

<p>
Our input is processed and sent to the business logic and an outcome is created.  But let's really dive into what's going on here
in our first phase of processing.  How does bash know what to do with this input?  What about sending input form one
place into another as in pipes, or i/o redirects?
</p>

<p>
Before we talk about how bash actually works and its interations with the kernel, let's first take a step back from all
of this.  A trick that I commonly use is to think about a complex system that might be a bit overwhelming, and think
about what it's doing at the 10k foot view.  Then I try to map out how, at a very high level, how I would go about trying
to create a thing that does the basics of what I'm seeing in front of me.
</p>

<p>
Basically bash is just a job control system with a complex parser system.  But we can break this down into a series
of stages:
</p>

<ul>
    <li>When the user hits enter, something should be able to interpret the input and break it down into parts that are used later.</li>
    <li>For each part, do something with the part.  Some parts with be commands, some parts will be files handlers.</li>
    <li>Ensure the proper execution order of each part.</li>
    <li>Ensure that each part can be tracked and nothing gets lost.</li>
    <li>Give the user some indication of success or failure.</li>
</ul>

<p>
Bash is basically years of churning on these basic parts with lots of learnings baked into the process.  But at a high
level it's basically just a an input processor, job controler, and output handler.  Which also describes almost all
of the things in our world, from mobile devices to web sites and everything in between.
</p>

<p>
Given the command above, when you hit enter you're invoking the text parsing functions within bash.  This part isn't actually
any form of C or C++, it's actually YACC.  YACC is the thing that is going to interpret all parts of what we've just given
as input.  The YACC scripts are giving us an incredably rich tapsitry of interpritation to build on.  This is how we can
create control structures like if conditionals and for loops, and even send input from one thing into another thing.
</p>

<p>
Once YACC has done the work to interpret the various symbols, bash will create a system of jobs for us that will help
control the flow of things.  This is important because we can't have things running out of order.  Order really matters
here, but it gets really tricky.  For example, we want the file handler to be created for the `txt` file, but we want
to hold it open until we're ready and have data to send to the file.
</p>

<p>
There are things that we can do to the operation of our command after we've hit enter.  We can stop the command all
together, or we can alter its state in various ways.  We do this by sending signals.  Signals are more of a kernel
level thing, but bash is doing quite a bit of work to ensure that we have proper signal handling at the proper time
during the execution of any command.  In this case it's unlikely that we'd need to send a signal at all, but there
might be cases where more long-running commands need to be killed off.  In that case we can send the kill signal
( SIGHUP ) to the running process ( not bash itself! ) which will cause the command to terminate.  Bash will recognize
that the process has been killed and flush it from the job list.  Anything that depends on the command that was killed
is also terminated as it won't be able to finish its execution as requested.
</p>

<p>
Once our input has been processed, we'll end up with a series of jobs that will be in variying states.  Bash is going
to do the work to monitor each job and its state.  In this case, the first thing that will execute will be the `ls`
command.  We'll get more into how things execute a little later, but for now we're going to state that two things are
in our job queue at this point:
</p>

<ul>
    <li>fork(ls) ( with some flags )</li>
    <li>open(txt)</li>
</ul>

<p>
We'll get into what fork() and open() are doing later, but for now, let's focus on this example.  The fork() action
is going to create a kernel process, this process and its lifecycle state is tracked by the bash process, which is also
another process in the process table.  The job control process system also fires up a process for tracking the open
file handle.  The file handle gives us us a few channels of operation.
</p>

<p>
Bash is an evolution of Unix and POSIX just like you're an evolution of your grandparents.  To that end, in the beginning
of the Unix world efficiency was the name of the game.  If we started bash in the world of dynamically allocated TB sized
disks, then we would probalby write the output of `ls` to a tmp file, or even memory, then send the content to the
output file.  Efficency means connecting the output of `ls` directly to the input of the file handler for `txt`.
</p>

<p>
Now here's where it gets really interesting.  Let's switch this example up and change it slightly with the following
command:
</p>

{% highlight shell %}
grep "String" huge_file | head
{% endhighlight %}

<p>
Note that in this case we're using "|" instead of ">" this is slightly different as bash will actualy fire up both
commands with `fork()` which means both commands are running at the same time.  But, just like the previous example
bash will connect the output from the left command to the input of the right command.
</p>

<p>
The exciting part about this is that the `head` will close after 10 lines of input.  When `head` closes, bash will also
close the `grep` process.  This is exciting because you don't end up wasting a ton of time and resources parsing data
you don't need.  Once the requirements for `head` have been met, just close the entire pipeline.  That's very helpful.
</p>





